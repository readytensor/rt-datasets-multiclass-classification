{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450a73e0",
   "metadata": {},
   "source": [
    "# Six Concentric Spheres Dataset\n",
    "This script generates a synthetic dataset, named \"Six Concentric Spheres\", consisting of a series of 3D spheres nested within each other. Each sphere forms a distinct class, presenting a multi-class classification problem in a 3-dimensional space. The classification task is non-trivial due to the close proximity and overlaps of points belonging to different classes.\n",
    "\n",
    "The generation process begins with setting parameters like the number of samples for each sphere, the radii of the spheres, and the noise level. The points are then generated on each sphere using uniformly distributed random angles (azimuth and inclination). Gaussian noise is added to these points to simulate real-world inconsistencies and make the classification task more challenging.\n",
    "\n",
    "After the points on each sphere are generated, the script augments the dataset with additional features to further increase its complexity. These additional features include dummy variables with random values, features that are correlated with the original 'x', 'y', and 'z' features, and missing values introduced at random across the features.\n",
    "\n",
    "Each record in the dataset contains a unique ID, the 'x', 'y', 'z' coordinates of the point, the target class (sphere number), and additional features. The target classes are represented as integers, starting from 0 for the innermost sphere and increasing for the outer spheres.\n",
    "\n",
    "The script concludes with a 3D visualization of the dataset, using different colors, transparency levels, and marker sizes for each class. The visualization offers a clear picture of the nested spheres and their respective classes, helping to understand the intricacies of the classification task at hand.\n",
    "\n",
    "The resulting Concentric Spheres dataset, with its multiclass, multi-feature complexity and inherent noise, offers a robust environment for benchmarking, understanding, and illustrating the performance of various machine learning algorithms. Despite its synthetic nature, it closely resembles practical scenarios where classification boundaries are not easily distinguishable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "692de854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "46711af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'six_concentric_spheres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5994fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'./../../processed/{dataset_name}/'\n",
    "outp_fname = os.path.join(output_dir, f'{dataset_name}.csv')\n",
    "outp_chart_fname = os.path.join(output_dir, f'{dataset_name}_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6290e1d",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b422210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value=0):\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0a3e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_id(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d50a0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_points_on_sphere(num_points, radius=1, noise_std_dev=0.1):\n",
    "    points = np.empty((num_points, 3))\n",
    "\n",
    "    phi = 2 * np.pi * np.random.rand(num_points)  # azimuthal angle\n",
    "    z = radius * (2 * np.random.rand(num_points) - 1)  # z coordinates\n",
    "    r_xy = np.sqrt(radius**2 - z**2)  # projected radius in the xy-plane\n",
    "\n",
    "    points[:, 0] = r_xy * np.cos(phi)  # x coordinates\n",
    "    points[:, 1] = r_xy * np.sin(phi)  # y coordinates\n",
    "    points[:, 2] = z\n",
    "\n",
    "    # Add Gaussian noise to each point\n",
    "    noise = np.random.normal(scale=noise_std_dev, size=points.shape)\n",
    "    points += noise\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c38c140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_concentric_spheres(\n",
    "        num_samples=[240, 735, 1500, 2535, 3840, 5415], \n",
    "        radii=[4, 7, 10, 13, 16, 19]):\n",
    "\n",
    "    dfs = []\n",
    "    for i, (num_points, radius) in enumerate(zip(num_samples, radii)):\n",
    "        points = generate_noisy_points_on_sphere(num_points, radius=radius)\n",
    "        df = pd.DataFrame(points, columns=['x', 'y', 'z'])\n",
    "        df.insert(0, \"sphere\", i)\n",
    "        dfs.append(df)\n",
    "\n",
    "    data = pd.concat(dfs)\n",
    "    data.insert(0, \"id\",  [generate_id() for _ in range(sum(num_samples))])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "85925925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dummy_features(df, num_features=67):\n",
    "    for i in range(num_features):\n",
    "        df[f'dummy_{i+1}'] = np.random.rand(len(df))\n",
    "    return df\n",
    "\n",
    "def add_correlated_features(df, correlation_factor=0.5):\n",
    "    for feature in ['x', 'y', 'z']:\n",
    "        noise = np.random.normal(scale=0.1, size=len(df))\n",
    "        df[f'corr_{feature}'] = df[feature] * correlation_factor + noise\n",
    "    return df\n",
    "\n",
    "def add_missing_values(df, missing_fraction=0.05):\n",
    "    for column in df.columns:\n",
    "        if column not in ['id', 'sphere']:\n",
    "            num_missing = int(missing_fraction * len(df))\n",
    "            missing_indices = np.random.choice(df.index, num_missing, replace=False)\n",
    "            df.loc[missing_indices, column] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "461f3dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14265, 75)\n",
      "       id  sphere         x         y         z   dummy_1   dummy_2   dummy_3  \\\n",
      "0  Y0CQ65     0.0 -2.634570 -0.867808       NaN       NaN       NaN  0.430480   \n",
      "1  ZT4WN6     0.0 -0.671839 -2.486998 -3.159058  0.306340  0.677972  0.516750   \n",
      "2  ISIGQ8     0.0 -3.108666 -2.430462  0.143982       NaN  0.845339  0.916863   \n",
      "3  JTGEV4     0.0 -2.552143 -0.689412 -3.100517  0.056274  0.091103  0.819825   \n",
      "4  9GW1UN     0.0       NaN  1.751371  1.565067  0.443345       NaN  0.981520   \n",
      "\n",
      "    dummy_4   dummy_5  ...  dummy_61  dummy_62  dummy_63  dummy_64  dummy_65  \\\n",
      "0  0.581152       NaN  ...  0.648593       NaN  0.032347       NaN  0.110808   \n",
      "1  0.769210  0.449406  ...  0.691329       NaN  0.757875  0.479449  0.866878   \n",
      "2  0.469258  0.964725  ...  0.910632  0.777139  0.524058  0.846995  0.646210   \n",
      "3       NaN  0.547786  ...  0.684112       NaN  0.167371  0.073030  0.409908   \n",
      "4       NaN  0.729234  ...  0.469190  0.410747  0.426167  0.444393  0.576064   \n",
      "\n",
      "   dummy_66  dummy_67    corr_x    corr_y    corr_z  \n",
      "0       NaN  0.520042 -1.317023 -0.448958  1.420843  \n",
      "1  0.714422  0.614546       NaN -1.159761 -1.459807  \n",
      "2  0.088305  0.741793 -1.417480 -1.116551  0.053193  \n",
      "3  0.078720  0.535487 -1.328158 -0.515638       NaN  \n",
      "4  0.630832  0.609368 -1.448748  0.843352  0.763732  \n",
      "\n",
      "[5 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "set_seed()\n",
    "\n",
    "# Generate original dataset\n",
    "data = generate_concentric_spheres()\n",
    "\n",
    "# Add dummy features\n",
    "data = add_dummy_features(data)\n",
    "\n",
    "# Add correlated features\n",
    "data = add_correlated_features(data)\n",
    "\n",
    "# Add missing values\n",
    "data = add_missing_values(data, missing_fraction=0.05)\n",
    "\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa80849",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "14dfcb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_3d_scatter(X, labels, filename=None):\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, 6))  # Create a color map from dark to light\n",
    "    alphas = np.linspace(0.4, 0.1, 6)  # Create transparency values from opaque to transparent\n",
    "    sizes = np.linspace(30, 10, 6)  # Create marker sizes from large to small\n",
    "\n",
    "    for target in range(6):\n",
    "        mask = labels == target\n",
    "        ax.scatter(X[mask, 0], X[mask, 1], X[mask, 2], color=colors[target],\n",
    "                    label=f\"Class {target}\", alpha=alphas[target], s=sizes[target])\n",
    "\n",
    "    plt.title('Synthetic 3D Concentric Spheres Dataset\\n'  # main title\n",
    "              '(Main dimensions defining the classes: x, y, z)',  # subtitle\n",
    "              loc='center', fontsize=14)  # place the title to the left with font size 12\n",
    "\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    # Move the legend to the right side with bbox_to_anchor argument\n",
    "    ax.legend(bbox_to_anchor=(1.1, 0.6), loc='center left')\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "204690ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3803\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3804\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39540\\2486389600.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_and_save_3d_scatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"z\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutp_chart_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3804\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3805\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3806\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3807\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3804\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3805\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3806\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3807\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "plot_and_save_3d_scatter(data[[\"x\", \"y\", \"z\"]].values, data[\"sphere\"], outp_chart_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0d52f",
   "metadata": {},
   "source": [
    "# Save Main Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(outp_fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544354b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

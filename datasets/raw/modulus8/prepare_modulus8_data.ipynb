{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450a73e0",
   "metadata": {},
   "source": [
    "# Modulus8 Dataset\n",
    "\n",
    "This script generates a synthetic dataset, named \"Modulus8\", designed to challenge multi-class classification models in a high-dimensional feature space. \n",
    "\n",
    "The dataset generation commences by creating random integer values between 0 and 100 for five predictor features. To determine the target class, the values of the five features are summed, followed by a modulus operation with 8. The outcome of this modulus operation is the class label, which can range from 0 to 7. This methodological twist ensures that classes aren't merely based on distinct value ranges but rather on a summation across multiple features, complicated further by a modulus operation. Furthermore, class distribution is uneven as follows:  \n",
    "- 100 samples for class 0\n",
    "- 200 for class 1\n",
    "- 300 for class 2\n",
    "- 500 for class 3\n",
    "- 800 for class 4\n",
    "- 1,200 for class 5\n",
    "- 2,000 for class 6, and \n",
    "- 3,000 for class 7\n",
    "\n",
    "Every record in the \"Modulus8\" dataset includes a unique ID, the five features, and the target class. The target class, represented as integers between 0 and 7, stems from the modulus operation result. \n",
    "\n",
    "The very architecture of this dataset creates a formidable classification challenge. With the entangled summation and modulus operations, combined with uneven class distributions, pinpointing class boundaries becomes a non-trivial task for models.\n",
    "\n",
    "The resulting \"Modulus8\" dataset, with its multifaceted design and inherent intricacies, offers a rigorous testing ground for machine learning enthusiasts. Although synthetically devised, it mirrors complexities encountered in real-world scenarios, truly evaluating the proficiency of various classification algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "692de854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "46711af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'modulus8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e5994fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'./../../processed/{dataset_name}/'\n",
    "outp_fname = os.path.join(output_dir, f'{dataset_name}.csv')\n",
    "outp_chart_fname = os.path.join(output_dir, f'{dataset_name}_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6290e1d",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "0b422210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value=0):\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d50a0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(n_samples: int, n_predictors: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Generate random predictor for a specified number of samples.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples (int): Number of samples to generate.\n",
    "    - n_predictors (int): Number of predictor features.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Generated predictor values, dummy values, computed class labels.\n",
    "    \"\"\"\n",
    "    predictors = np.random.randint(0, 101, size=(n_samples, n_predictors))\n",
    "    labels = (predictors.sum(axis=1) % 8)\n",
    "    \n",
    "    return predictors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "45216ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_class_data(\n",
    "        predictors: np.array,\n",
    "        labels: np.array,\n",
    "        class_label: int,\n",
    "        n_samples: int\n",
    "    ) -> tuple:\n",
    "    \"\"\"\n",
    "    Subsample predictor to match a specified class label and number of samples.\n",
    "    \n",
    "    Parameters:\n",
    "    - predictors (np.array): Predictor values.\n",
    "    - labels (np.array): Computed class labels.\n",
    "    - class_label (int): Desired class label.\n",
    "    - n_samples (int): Number of samples to subsample.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Subsampled predictor values, dummy values, target values.\n",
    "    \"\"\"\n",
    "    mask = (labels == class_label)\n",
    "    \n",
    "    selected_predictors = predictors[mask][:n_samples]\n",
    "    selected_targets = np.array([class_label] * n_samples)\n",
    "    \n",
    "    return selected_predictors, selected_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5c0d5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(\n",
    "        class_samples: list = [100, 200, 300, 500, 800, 1200, 2000, 3000],\n",
    "        n_predictors: int = 5,\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a synthetic dataset for multiclass classification.\n",
    "    \n",
    "    Parameters:\n",
    "    - class_samples (list): A list containing the number of samples desired for each class.\n",
    "    - n_predictors (int): Number of actual predictor features.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A pandas DataFrame containing the generated dataset.\n",
    "    \"\"\"   \n",
    "    all_predictors, all_dummies, all_targets = [], [], []\n",
    "    \n",
    "    predictors, labels = generate_samples(25000, n_predictors)\n",
    "    \n",
    "    for class_label in range(8):\n",
    "        selected_predictors, selected_targets = subsample_class_data(\n",
    "            predictors, labels, class_label, class_samples[class_label]\n",
    "        )\n",
    "        \n",
    "        all_predictors.append(selected_predictors)\n",
    "        all_targets.append(selected_targets)\n",
    "\n",
    "    # Concatenate the results\n",
    "    predictors = np.vstack(all_predictors)\n",
    "    target = np.concatenate(all_targets)\n",
    "\n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame(\n",
    "        predictors,\n",
    "        columns=[f'predictor_{i+1}' for i in range(n_predictors)]\n",
    "    )\n",
    "    \n",
    "    # Add the target column\n",
    "    df['target'] = target\n",
    "    \n",
    "    # Shuffle data\n",
    "    df = df.sample(frac=1.0, replace=False)\n",
    "\n",
    "    # Add an ID column\n",
    "    df['id'] = range(len(df))\n",
    "    \n",
    "    # Arrange the columns\n",
    "    df = df[['id'] + [col for col in df if col != 'id']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "461f3dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8100, 7)\n",
      "      id  predictor_1  predictor_2  predictor_3  predictor_4  predictor_5  \\\n",
      "5679   0           13           17           30           82           81   \n",
      "1894   1            9           24            2           27           62   \n",
      "1787   2            0           65           83            7           57   \n",
      "7330   3           57           86           29           77           46   \n",
      "8053   4           45           24           27           76           19   \n",
      "\n",
      "      target  \n",
      "5679       7  \n",
      "1894       4  \n",
      "1787       4  \n",
      "7330       7  \n",
      "8053       7  \n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "set_seed()\n",
    "\n",
    "n_predictors = 5\n",
    "\n",
    "# Generate original dataset\n",
    "data = generate_dataset(\n",
    "    class_samples = [100, 200, 300, 500, 800, 1200, 2000, 3000],\n",
    "    n_predictors = n_predictors\n",
    ")\n",
    "\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5379c837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    3000\n",
       "6    2000\n",
       "5    1200\n",
       "4     800\n",
       "3     500\n",
       "2     300\n",
       "1     200\n",
       "0     100\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79c79b",
   "metadata": {},
   "source": [
    "# Verify data was correctly generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "01965ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def verify_target_calculation(df: pd.DataFrame, n_predictors: int = 50) -> bool:\n",
    "    \"\"\"\n",
    "    Verify that the target is correctly calculated based on the predictor features.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The generated dataset.\n",
    "    - n_predictors (int): Number of predictor features.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if all targets are correctly calculated, False otherwise.\n",
    "    \"\"\"\n",
    "    # Calculate the target based on the predictor features\n",
    "    calculated_targets = df.iloc[:, 1:n_predictors+1].sum(axis=1) % 8\n",
    "\n",
    "    # Check if the calculated targets match the actual targets in the dataframe\n",
    "    matches = (calculated_targets == df['target']).all()\n",
    "\n",
    "    # Check the counts per class\n",
    "    class_counts = df['target'].value_counts().sort_index().values\n",
    "    desired_counts = [100, 200, 300, 500, 800, 1200, 2000, 3000]\n",
    "\n",
    "    correct_counts = all(count == desired for count, desired in zip(class_counts, desired_counts))\n",
    "\n",
    "    return matches and correct_counts\n",
    "\n",
    "print(verify_target_calculation(data, n_predictors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0d52f",
   "metadata": {},
   "source": [
    "# Save Main Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5ab3560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(outp_fname, index=False, float_format=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544354b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
